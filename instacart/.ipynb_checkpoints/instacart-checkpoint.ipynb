{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instacart Market Basket Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index\n",
    "1. Extract the data and fill the gaps\n",
    "2. Understand the data\n",
    "3. Preprocesssing stage\n",
    "4. Training different models to set a Benchmark\n",
    "5. Improvise the Model and Repeat\n",
    "6. Predict on Test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# List all the data we have.\n",
    "print(os.listdir('data'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Extract the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aisles      = pd.read_csv('data/aisles.csv')\n",
    "departments = pd.read_csv('data/departments.csv')\n",
    "order_prior = pd.read_csv('data/order_products__prior.csv')\n",
    "order_train = pd.read_csv('data/order_products__train.csv')\n",
    "orders      = pd.read_csv('data/orders.csv')\n",
    "products    = pd.read_csv('data/products.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aisles.shape)\n",
    "print(aisles.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(departments.shape)\n",
    "print(departments.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (order_prior.shape)\n",
    "print(order_prior.sort_values('order_id').head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(order_train.shape)\n",
    "print(order_train[ order_train['order_id']==1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(orders.shape,'\\n',orders.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(products.shape)\n",
    "print(products.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. Understanding Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Chance of Items being ordered for first time\n",
    "Percentage of old items in order vs new items in orders ~ 60%\n",
    "So even though we predict all the items that will be reordered there is a 40% chance that a new item might be added by \n",
    "the user with the next order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_train_data = order_train\n",
    "reordered = (detailed_train_data[detailed_train_data['reordered']==1].shape[0])\n",
    "not_reordered = (detailed_train_data[detailed_train_data['reordered']==0].shape[0])\n",
    "print( \"percentage of new orders =\", reordered*100 / (reordered+not_reordered))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see which group of items are popularly reordered in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Joining orders , products and departments to give some meaningful names to each product\n",
    "\n",
    "detailed_train_data = pd.merge(order_train,products,how='left', left_on=['product_id'], right_on = ['product_id'])\n",
    "detailed_train_data = pd.merge(detailed_train_data,departments,how='left', left_on=['department_id'], right_on = ['department_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract only elements which have been ordered before\n",
    "group = detailed_train_data[detailed_train_data['reordered']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grouping according to individual department and getting how many orders have been placed categorically\n",
    "group = group[['department','reordered','department_id']].groupby(['department','department_id']).sum()\n",
    "group = group.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Each department is popular in it's own way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pie chart below shows that the quantitiy of reordered items of produce are the most, followed by dairy eggs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = group.sort_values(by=['reordered'],ascending=[False])\n",
    "temp = group.reordered\n",
    "label = np.array(group.department)\n",
    "values = np.array(100*temp/temp.sum())\n",
    "sns.set(font_scale=1.5)\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.pie(values, labels=label, autopct='%1.1f%%', startangle=210)\n",
    "plt.title(\"Departments distribution\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2.1 It's not always about the quantity    \n",
    "Although produce has more number of reorders, we need to see how many of the total produce orders are actually reordered. This explanation says dairy eggs have higher rate of reorder. Say if there are 20 orders although 7 of the orders of produce are reordered and 3 orders of dairy are reordered, there might have been a total of 10 produce, but only 3 of dairy all of which are reordered. Thus predicting dairy eggs to be reordered more would give us better results.\n",
    "\n",
    "This analysis based on the trainig data gives us an idea that few categories are reordered relatively very high compared to others but It's not a fair way to estimate which category is being reordered more, since say if all the orders in babies department have been re-ordered It's corresponding measure should be high. So we should consider    \n",
    "\n",
    "                       (total reorders in a category) /(total orders in each category)\n",
    "                       \n",
    "As we can see below though number of reorders snacks being high compared to say, pets. Ratio doesn't indicate the same. This gives a more clear picture say even if number of orders of snacks were relatively high, they are not quite reordered in the same way as pet products were.\n",
    "\n",
    "This could indicate how we always try to experiment with snacks and also not to exclude different flavors for each product we have which might cause this behaviour as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_group = detailed_train_data.groupby(['department','department_id']).count().reset_index()\n",
    "\n",
    "group = group[['department','reordered','department_id']].groupby(['department','department_id']).sum()\n",
    "group = group.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratio = pd.DataFrame({'department':total_group.department,'ratio':group['reordered']/total_group.reordered}).sort_values('ratio',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.set(font_scale=3) \n",
    "sns.pointplot(ratio.department,(ratio.ratio))\n",
    "plt.xlabel('Department', fontsize=25)\n",
    "plt.ylabel('Reorder ratio', fontsize=25)\n",
    "plt.title(\"Rate of Reorders\", fontsize=30)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_products = pd.merge(products,departments,how='left', left_on=['department_id'], right_on = ['department_id'])\n",
    "total_products = total_products.groupby('department').agg('count').reset_index().sort_values('product_id',ascending=False)\n",
    "total_products.product_id = total_products.product_id \n",
    "plt.figure(figsize=(20,10))\n",
    "sns.set(font_scale=3) \n",
    "sns.pointplot(total_products.department,total_products.product_id)\n",
    "plt.xlabel('Department', fontsize=25)\n",
    "plt.ylabel('Number of Products', fontsize=25)\n",
    "plt.title(\"Size of each Department\", fontsize=30)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joint = pd.merge(total_products[['department','product_id']],ratio,on='department').reset_index()\n",
    "joint.columns=['i','department','product_count','reorder_ratio']\n",
    "scaler = MinMaxScaler()\n",
    "joint[['product_count','reorder_ratio']] = scaler.fit_transform(joint[['product_count','reorder_ratio']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.set(font_scale=3) \n",
    "sns.pointplot(joint.department,joint.reorder_ratio)\n",
    "sns.pointplot(joint.department,joint.product_count,color='red')\n",
    "plt.xlabel('Department', fontsize=25)\n",
    "plt.ylabel('Normalized value', fontsize=25)\n",
    "plt.title(\"Red = product_count, Blue = reorder ratio\", fontsize=30)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freedom of more\n",
    "When users have more products say in case of first 3 departments the reorder ration is very less except for snacks.\n",
    "It might indicate that these departments are very experimental and predicting these orders would be highly unlikely since they are available in abundance and users are not willing to order them again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average time between reorders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_records = orders.shape[0]\n",
    "print(orders.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prior_orders = orders[orders.eval_set == 'prior']\n",
    "train_orders = orders[orders.eval_set == 'train']\n",
    "test_orders  = orders[orders.eval_set == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prior_data = pd.merge(prior_orders,order_prior)\n",
    "train_data = pd.merge(train_orders,order_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prior_data.sort_values(by=['user_id','order_number']).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create list of products that needs to be predicted.\n",
    "predict_products = pd.DataFrame()\n",
    "# select distinct user id's\n",
    "predict_products['user_id'] = prior_data['user_id'].drop_duplicates()\n",
    "temp = pd.DataFrame( prior_data.groupby(['user_id'])['product_id'].apply(set).reset_index() )\n",
    "predict_products = pd.merge(predict_products,temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict_products[predict_products['user_id']==3]['product_id'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Feature set\n",
    "\n",
    "To create a benchmark I\"ll be using 4 basic features.\n",
    "1. Reorder ratio ( Number of times product has been rerordered )\n",
    "2. Aisle ID ( The aisle from which the product is selected )\n",
    "3. Add to cart order ( The average add to cart order of the product )\n",
    "4. Avg number of items in the cart ( This would be the user property )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_user_order   = pd.DataFrame(prior_data.groupby(['user_id','order_id']).size().reset_index())\n",
    "prior_user_product = prior_data[['user_id','order_id','product_id','reordered','add_to_cart_order','order_id']].groupby(['user_id','product_id']).agg(['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Two features obtained.\n",
    "feature_add_order = pd.DataFrame(prior_user_product['add_to_cart_order']['mean']).reset_index()\n",
    "feature_reorder   = pd.DataFrame(prior_user_product['reordered']['mean']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To calculate avg number of orders in a user basket, we need to group twice.\n",
    "prior_user_order.columns=['user_id','order_number','num_products']\n",
    "prior_user_order = prior_user_order[['user_id','num_products','order_id']].groupby('user_id').agg(['mean'])\n",
    "feature_num_orders = pd.DataFrame((b['num_products']['mean'])).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(feature_add_order.head(),feature_num_orders.head(),feature_reorder.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_all = feature_add_order.merge(feature_reorder,on=(['user_id','product_id']),suffixes=('_add_order','_reorder'))\n",
    "\n",
    "feature_all = feature_all.merge(feature_num_orders,on=(['user_id']),suffixes=('_','_num_orders'))\n",
    "\n",
    "feature_all = feature_all.merge(products[['product_id','aisle_id']],on=(['product_id']))\n",
    "\n",
    "feature_all = feature_all.rename(columns={'mean':'avg_orders','mean_add_order':'avg_add_order','mean_reorder':'reorder_ratio'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These are the features for all products. Now we have to create target variables from train data.\n",
    "print(feature_all[ feature_all.user_id==1 ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
